# Responsible AI ðŸ¤–

It is important for anyone using AI to understand the impact their solutions can have on users and society. These may become problematic if not properly managed because of the nature of how AI works and makes decisions. **These models are dependent on the data they are trained on.**

Users are drawn to AI because of the human-like responses they can provide. However, this can sway users into placing a lot of trust in the application to make decisions for them. The potential for AI to harm users is real and must be taken seriously. Microsoft uses six principles to guide the development and use of AI:

1. **Fairness**: AI systems should treat all users fairly and avoid bias. AI should not make decisions that unfairly favor or disadvantage certain groups of people <u>based on gender, ethnicity, or personal characteristics.</u>
2. **Reliability and Safety**: AI systems should be reliable and safe to use, especially in areas where human life is at risk, such a <u>self driving cars or medical diagnosis.</u>
3. **Privacy and Security**: AI systems should protect user privacy and data security <u>in training and production.</u>
4. **Inclusiveness**: AI systems should be inclusive and accessible to all users, <u>no matter physical ability, gender, sexual orientation, or other factors.</u>
5. **Transparency**: Users should understand <u>how AI works, what data it uses, and its limitations.</u>
6. **Accountability**: People should be accountable for the decisions made by AI systems. <U>This should be governed by frameworks that ensure responsible use of AI.</u>

By adhering to these principles, developers can create AI solutions that are not only effective but also ethical and responsible.

## Up Next: Lab 1
[Develop generative AI solutions in Azure AI Foundry portal.](AI-100/PrepareAIDevProject.md)